{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Μέλη Ομάδας:\n",
    "- Ευάγγελος Λευτάκης : 3200093\n",
    "- Ρέα Σκλήκα : 3210192 \n",
    "- Σοφία Σωτηρίου : 3210181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First We Prepare the train, dev and test data and create a binary representation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "(temp_x_train_imdb, temp_y_train_imdb), (x_test_imdb, y_test_imdb) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "split_index = int(0.8 * len(temp_x_train_imdb))  # 80% for training, 20% for dev\n",
    "\n",
    "x_train_imdb, y_train_imdb = temp_x_train_imdb[:split_index], temp_y_train_imdb[:split_index]\n",
    "x_dev_imdb, y_dev_imdb = temp_x_train_imdb[split_index:], temp_y_train_imdb[split_index:]\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_imdb])\n",
    "x_dev_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_dev_imdb])\n",
    "x_test_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_imdb])\n",
    "\n",
    "binary_vectorizer = CountVectorizer(binary=True, min_df=100)\n",
    "x_train_imdb_binary = binary_vectorizer.fit_transform(x_train_imdb)\n",
    "x_dev_imdb_binary = binary_vectorizer.transform(x_dev_imdb)\n",
    "x_test_imdb_binary = binary_vectorizer.transform(x_test_imdb)\n",
    "print(\n",
    "    'Vocabulary size:', len(binary_vectorizer.vocabulary_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
